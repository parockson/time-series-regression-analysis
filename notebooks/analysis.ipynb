{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series Forecasting on Corporation Favorita Grocery Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Objective:** The business objective is to optimize inventory management by accurately **forecasting product demand** across various locations, ensuring adequate stock levels to meet customer demand while minimizing stockouts and overstock situations.\n",
    "\n",
    "\n",
    "**Understanding the Current Situation:** The understanding of the current situation involves a comprehensive analysis of Corporation Favorita's inventory management and demand forecasting processes. This encompasses reviewing historical sales data, inventory levels, and customer demand patterns to identify trends and fluctuations. Additionally, it involves evaluating the effectiveness of existing processes, technology infrastructure, and decision-making frameworks. Consultation with stakeholders from various departments helps gather insights into business requirements, challenges, and opportunities. External factors such as market dynamics, economic conditions, and regulatory requirements are also considered. This holistic understanding forms the basis for developing strategies and implementing data-driven solutions to optimize inventory management and meet business objectives. \n",
    "\n",
    "**Data Mining Goals:** The aim of data mining is to build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores.. \n",
    "\n",
    "**Project Plan:** The project plan involves following the CRISP-DM framework to develop machine learning models for forecasting product demand in various locations for Corporation Favorita. This includes conducting a thorough data understanding phase to gather and explore relevant datasets, followed by data preparation to preprocess and clean the data for analysis. The modeling phase will involve building and evaluating machine learning models using techniques such as time series forecasting, regression analysis, and machine learning algorithms. Evaluation metrics such as Mean Absolute Error (MAE) and Mean Squared Error (MSE) will be used to assess model performance. Finally, the selected model will be deployed into production to generate forecasts for product demand, with ongoing monitoring and refinement as needed to ensure alignment with business objectives and requirements.\n",
    "\n",
    "**Data for the Project:**\n",
    "\n",
    "The data for this projects has been divided into 2. The first data set are for training and evaluation the machine learning model  while the last data set is for testing the model. \n",
    "\n",
    "The training dataset can be found in a database which will have to be accessed remotely and a zip file hosted on Github repository.\n",
    "\n",
    "The test dataset for this project can be found in OneDrive.\n",
    "\n",
    "**File Descriptions and Data Field Information**\n",
    "\n",
    "**train.csv**\n",
    "\n",
    "-   The training data, comprising time series of features store_nbr, family, \n",
    "    and onpromotion as well as the target sales.\n",
    "\n",
    "-   **store_nbr** identifies the store at which the products are sold.\n",
    "\n",
    "-   **family** identifies the type of product sold.\n",
    "\n",
    "-   **sales** gives the total sales for a product family at a particular store\n",
    "    at a given date. Fractional values are possible since products can be sold in \n",
    "    fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n",
    "\n",
    "-   **onpromotion** gives the total number of items in a product family that\n",
    "    were being promoted at a store at a given date.\n",
    "\n",
    "**test.csv**\n",
    "\n",
    "-   The test data, having the same features as the training data. You will predict the target sales for the dates in this file.\n",
    "\n",
    "-   The dates in the test data are for the 15 days after the last date in the training data.\n",
    "\n",
    "**transaction.csv**\n",
    "\n",
    "-   Contains date, store_nbr and transaction made on that specific date.\n",
    "\n",
    "**sample_submission.csv**\n",
    "\n",
    "-   A sample submission file in the correct format.\n",
    "\n",
    "**stores.csv**\n",
    "\n",
    "-   Store metadata, including city, state, type, and cluster.\n",
    "\n",
    "-   cluster is a grouping of similar stores.\n",
    "\n",
    "**oil.csv**\n",
    "\n",
    "-   **Daily oil price** which includes values during both the train and\n",
    "     test data timeframes. (Ecuador is an oil-dependent country and its\n",
    "     economical health is highly vulnerable to shocks in oil prices.)\n",
    "\n",
    "**holidays_events.csv**\n",
    "-   Holidays and Events, with metadata\n",
    "\n",
    "> **NOTE**: The attention was to be paid particularly to the **transferred** column, > > as explained. It was noted that a holiday officially designated as **transferred** > fell on a specific calendar day but had been moved to another date by the >  government. Such a transferred day was described as more akin to a normal day than a > holiday. To determine the day it was celebrated, it was instructed to locate the > corresponding row where the type was **Transfer.** An example was provided, citing the > holiday Independencia de Guayaquil, which was transferred from 2012-10-09 to > 2012-10-12, indicating that it was celebrated on 2012-10-12. It was clarified that > days labeled as **Bridge** were additional days added to a holiday to extend the break > across a long weekend. These additional days were often compensated for by **Work > Day,** which referred to a day not typically scheduled for work (e.g., Saturday) > meant to offset the extended holiday. Furthermore, it was mentioned that additional > holidays were days added to a regular calendar holiday, such as Christmas, > typically including Christmas Eve as a holiday.\n",
    "\n",
    "**Additional Notes**\n",
    "\n",
    "-   Wages in the public sector are paid every two weeks on the 15th and\n",
    "    on the last day of the month. Supermarket sales could be affected\n",
    "    by this.\n",
    "\n",
    "-   A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People\n",
    "    rallied in relief efforts donating water and other first need\n",
    "    products which greatly affected supermarket sales for several\n",
    "    weeks after the earthquake.\n",
    "\n",
    "\n",
    "### `Analytical Questions`:\n",
    "\n",
    "> 1. Is the train dataset complete (has all the required dates)?\n",
    "> 2. Which dates have the lowest and highest sales for each year (excluding days the store was closed)?\n",
    "> 3. Compare the sales for each month across the years and determine which month of which year had the highest sales.\n",
    "> 4. Did the earthquake impact sales?\n",
    "> 5. Are certain stores or groups of stores selling more products? (Cluster, city, state, type)\n",
    "> 6. Are sales affected by promotions, oil prices and holidays?\n",
    "> 7. What analysis can we get from the date and its extractable features?\n",
    "> 8. Which product family and stores did the promotions affect.\n",
    "> 9. What is the difference between RMSLE, RMSE, MSE (or why is the MAE greater than all of them?)\n",
    "> 10. Does the payment of wages in the public sector on the 15th and last days of the month influence the store sales.\n",
    "\n",
    "\n",
    "### `Hypotheses`\n",
    "\n",
    "`Null Hypothesis`: The payment of wages in the public sector on the 15th and last days of the month does not influence store sales.\n",
    "\n",
    "`Alternate Hypothesis`: The payment of wages in the public sector on the 15th and last days of the month significantly influences store sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATA UNDERSTANDING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis and Manipulation of Packages\n",
    "\n",
    "# Data handling\n",
    "import pyodbc     \n",
    "from dotenv import dotenv_values   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Vizualisation\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Feature Processing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn. linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn. preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Other packages\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display all columns and rows \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from SQL Database source\n",
    "\n",
    "# Load environment variables from .env file into a dictionary\n",
    "from dotenv import dotenv_values\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "server = os.getenv(\"DB_SERVER\")\n",
    "database = os.getenv(\"DB_NAME\")\n",
    "username = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "# Create a connection string\n",
    "connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "# Connect to the database\n",
    "import pyodbc\n",
    "connection = pyodbc.connect(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.120003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.199997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>47.650002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>46.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>46.459999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>45.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>47.259998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  dcoilwtico\n",
       "0     2013-01-01         NaN\n",
       "1     2013-01-02   93.139999\n",
       "2     2013-01-03   92.970001\n",
       "3     2013-01-04   93.120003\n",
       "4     2013-01-07   93.199997\n",
       "...          ...         ...\n",
       "1213  2017-08-25   47.650002\n",
       "1214  2017-08-28   46.400002\n",
       "1215  2017-08-29   46.459999\n",
       "1216  2017-08-30   45.959999\n",
       "1217  2017-08-31   47.259998\n",
       "\n",
       "[1218 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL query to extract the data \n",
    "query = \"SELECT * from dbo.oil\"\n",
    " \n",
    " # Execute the SQL query to load data into pandas Dataframe\n",
    "data_1= pd.read_sql(query, connection)\n",
    "\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Fundacion de Cuenca</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>Cantonizacion de Libertad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Cantonizacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     type    locale locale_name                    description  \\\n",
       "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
       "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
       "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
       "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
       "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
       "\n",
       "   transferred  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL query to extract the data \n",
    "query = \"SELECT * from dbo.holidays_events\"\n",
    " \n",
    " # Execute the SQL query to load data into pandas Dataframe\n",
    "data_2= pd.read_sql(query, connection)\n",
    "\n",
    "#data_2.to_csv('holidays_events.csv')#\n",
    "\n",
    "data_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr           city                           state type  cluster\n",
       "0          1          Quito                       Pichincha    D       13\n",
       "1          2          Quito                       Pichincha    D       13\n",
       "2          3          Quito                       Pichincha    D        8\n",
       "3          4          Quito                       Pichincha    D        9\n",
       "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL query to extract the data \n",
    "query = \"SELECT * from dbo.stores\"\n",
    " \n",
    " # Execute the SQL query to load data into pandas Dataframe\n",
    "data_3= pd.read_sql(query, connection)\n",
    "\n",
    "#data_3.to_csv('stores.csv')#\n",
    "\n",
    "data_3.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
